{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRQuFK_qMylf"
      },
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6l5ur2FMylg",
        "outputId": "ebaed295-de92-4aee-ad96-ef1bd0e1406e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch sentencepiece evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYQnC0DUMylh",
        "outputId": "01f194ea-f0ed-442d-e52e-b0109381fe2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 0, 'input': 'Suppose that you have an abstract for a scientific paper:    the short - term periodicities of the daily sunspot area fluctuations from august 1923 to october 1933 are discussed . for these data \\n the correlative analysis indicates negative correlation for the periodicity of about @xmath0 days , but the power spectrum analysis indicates a statistically significant peak in this time interval . \\n a new method of the diagnosis of an echo - effect in spectrum is proposed and it is stated that the 155-day periodicity is a harmonic of the periodicities from the interval of @xmath1 $ ] days .    the autocorrelation functions for the daily sunspot area fluctuations and for the fluctuations of the one rotation time interval in the northern hemisphere , separately for the whole solar cycle 16 and for the maximum activity period of this cycle do not show differences , especially in the interval of @xmath2 $ ] days . \\n it proves against the thesis of the existence of strong positive fluctuations of the about @xmath0-day interval in the maximum activity period of the solar cycle 16 in the northern hemisphere . \\n however , a similar analysis for data from the southern hemisphere indicates that there is the periodicity of about @xmath0 days in sunspot area data in the maximum activity period of the cycle 16 only . .\\nAnd you have already written the first three sentences of the full article: for about 20 years the problem of properties of short - term changes of solar activity has been considered extensively .\\nmany investigators studied the short - term periodicities of the various indices of solar activity .\\nseveral periodicities were detected , but the periodicities about 155 days and from the interval of @xmath3 $ ] days ( @xmath4 $ ] years ) are mentioned most often .. \\nPlease generate the next two sentences of the article', 'output': 'first of them was discovered by @xcite in the occurence rate of gamma - ray flares detected by the gamma - ray spectrometer aboard the _ solar maximum mission ( smm ) .\\nthis periodicity was confirmed for other solar flares data and for the same time period @xcite .', 'input_ids': [196098, 10701, 267, 121320, 6522, 533, 521, 783, 461, 83949, 332, 259, 262, 50577, 5057, 267, 287, 5700, 259, 264, 10886, 139213, 49944, 304, 287, 19671, 5693, 47466, 9340, 259, 126832, 876, 6540, 702, 10214, 69030, 288, 259, 37601, 295, 64539, 418, 22705, 345, 259, 260, 332, 259, 3824, 1624, 287, 7969, 9773, 17892, 54676, 299, 259, 32588, 317, 153000, 332, 287, 139213, 12070, 304, 1388, 5382, 259, 261, 1156, 287, 6665, 259, 119776, 17892, 54676, 299, 259, 262, 72832, 4621, 259, 20364, 85316, 281, 714, 1459, 41785, 259, 260, 259, 262, 1546, 10964, 304, 287, 60735, 417, 304, 461, 103706, 259, 264, 11232, 281, 259, 119776, 339, 5471, 345, 305, 609, 339, 6509, 285, 533, 287, 19945, 264, 4407, 139213, 12070, 339, 259, 262, 259, 204520, 304, 287, 139213, 49944, 702, 287, 41785, 304, 1160, 259, 439, 5382, 259, 260, 287, 1864, 297, 153000, 2835, 263, 332, 287, 19671, 5693, 47466, 9340, 259, 126832, 876, 6540, 305, 332, 287, 259, 126832, 876, 6540, 304, 287, 1371, 259, 92803, 1459, 41785, 281, 287, 259, 128667, 3599, 266, 111192, 259, 261, 259, 40335, 484, 332, 287, 18695, 26826, 259, 29592, 799, 305, 332, 287, 259, 23223, 30270, 8192, 304, 714, 259, 29592, 342, 776, 3153, 25297, 263, 259, 261, 259, 21230, 281, 287, 41785, 304, 1160, 259, 439, 5382, 259, 260, 609, 22864, 263, 259, 9825, 287, 259, 41361, 304, 287, 259, 63669, 304, 16322, 18205, 259, 126832, 876, 6540, 304, 287, 1388, 259, 264, 4407, 41785, 281, 287, 259, 23223, 30270, 8192, 304, 287, 26826, 259, 29592, 799, 281, 287, 259, 128667, 3599, 266, 111192, 259, 260, 259, 23286, 259, 261, 259, 262, 12020, 17892, 332, 1624, 702, 287, 259, 122474, 3599, 266, 111192, 54676, 299, 533, 2108, 339, 287, 139213, 12070, 304, 1388, 5382, 281, 5693, 47466, 9340, 1624, 281, 287, 259, 23223, 30270, 8192, 304, 287, 259, 29592, 799, 2469, 259, 260, 259, 260, 1829, 521, 783, 259, 13987, 259, 22243, 287, 2262, 7156, 101654, 299, 304, 287, 3622, 3737, 267, 332, 1388, 628, 3127, 287, 3091, 304, 37006, 304, 5700, 259, 264, 10886, 259, 25444, 304, 26826, 30270, 1070, 2101, 5071, 345, 79805, 71403, 259, 260, 3506, 17479, 19002, 26984, 285, 287, 5700, 259, 264, 10886, 139213, 49944, 304, 287, 259, 17250, 32181, 299, 304, 26826, 30270, 259, 260, 303, 14467, 139213, 49944, 2109, 269, 177110, 259, 261, 1156, 287, 139213, 49944, 1388, 19945, 5382, 305, 702, 287, 41785, 304, 1160, 259, 439, 5382, 274, 1160, 259, 439, 3127, 259, 271, 418, 19930, 345, 2250, 259, 18447, 259, 260, 260, 259, 9560, 259, 66792, 287, 6844, 2956, 101654, 299, 304, 287, 3737, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [2262, 304, 2486, 639, 31970, 345, 455, 281, 287, 29479, 6257, 12733, 304, 59330, 259, 264, 49652, 259, 111880, 263, 269, 177110, 455, 287, 59330, 259, 264, 49652, 108029, 62414, 259, 262, 11551, 287, 259, 290, 26826, 259, 23223, 32040, 274, 259, 263, 1109, 259, 271, 259, 260, 714, 139213, 12070, 639, 17686, 345, 332, 1904, 26826, 259, 111880, 263, 1624, 305, 332, 287, 4012, 1459, 8192, 259, 260, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "ds = load_dataset(\"scillm/scientific_papers-archive\", split=\"test\")\n",
        "\n",
        "# Select the first 1000 examples\n",
        "small_ds = ds.select(range(1000))\n",
        "\n",
        "# Preprocessing function to remove unwanted references\n",
        "def preprocess_text(text):\n",
        "    # Remove unwanted references like @xcite\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove anything that starts with @\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(examples):\n",
        "    # Preprocess articles and summaries\n",
        "    articles = [preprocess_text(article) for article in examples[\"input\"]]\n",
        "    outputs = [preprocess_text(output) for output in examples[\"output\"]]\n",
        "\n",
        "    # Add prefix to the articles\n",
        "    inputs = [\"summarize: \" + article for article in articles]\n",
        "\n",
        "    # Tokenize articles\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize summaries\n",
        "    labels = tokenizer(outputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Load mT5 model and tokenizer\n",
        "model_name = \"google/mt5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the smaller dataset\n",
        "tokenized_small_ds = small_ds.map(preprocess, batched=True)\n",
        "\n",
        "# Verify that the dataset is correctly tokenized\n",
        "print(tokenized_small_ds[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3soNCBZlMylh"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test set\n",
        "small_ds = ds.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt6YWrctMyli",
        "outputId": "1073384e-5978-415f-da7f-6bd112201f38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 6556,\n",
              " 'input': 'Provide a shorter version of the following research that reflects its organization into sections \"Introduction\\nMaterials and Methods\\nAnalysis\\nResults\\nDiscussion and Conclusion\".\\nResearch: reproductive tract infections ( rtis ) , including both sexually transmitted infections ( stis ) and non - sexually transmitted infections ( non - stis ) of the reproductive tract are responsible for major ill - health throughout the world.(1 ) world health organization estimates that each year there are over 340 million new cases of sexually transmitted infections in which 7585% occur in developing countries . in india\\nalone , 40 million new cases emerge each year.(2 ) a majority of women continue to suffer from rtis leading to complications like pelvic inflammatory disease ( pid ) , infertility , cervical cancer , postabortal , and puerperal sepsis , chronic pelvic pain , and ectopic pregnancy .\\nrtis in many cases are asymptomatic among women , making their detection and diagnosis difficult.(3 ) an effort has been made in this regard to detect rti cases among the women in the field practice area of urban health training centre ( uhtc ) , hubli , karnataka .\\nthe objective of the study was to know the prevalence of rtis among the reproductive age group women and the socio - demographic factors influencing the occurrence of the disease .\\nthis study was undertaken in the field practice area of uhtc , hubli , and reproductive age group women of 1545 years were identified for the study purpose .\\nit is a cross - sectional time bound study , conducted from september 2003 to august 2004 .\\nthe sample size 656 was calculated by taking into consideration 19% of women under 1545 years in urban community , at 95% confidence interval and 3% permissible error covering 1.96 under normal curve .\\nall houses in the field practice area were numbered by using a random numbering table .\\nhouses were selected on the basis of a simple random sampling technique until 656 women of the reproductive age group were covered in 520 families .\\na pretested structured pro forma was used to interview the women about their socio - demographic , reproductive history , current , and past rti symptoms .\\nthe syndromes related to rti as recommended...',\n",
              " 'output': 'Core Summary:  background : reproductive tract infections ( rtis ) is a global health problem including both sexually transmitted infections ( stis ) and non - sexually transmitted infections ( non - stis ) of the reproductive tract . \\n rti / sti is an important concern , as it possess risk for human immunodeficiency virus transmission . \\n hence a community study was done in hubli , in terms of active search of the cases based on the symptoms , clinical examination , and feasible laboratory tests along with providing treatment , counseling , and follow-up.objectives:the objective was to know the prevalence of rtis among the reproductive age group women and the socio - demographic factors influencing the occurrence of the disease.materials and methods : a cross - sectional study was done using a simple random sampling technique to select households . \\n a pretested structured pro forma was used to collect data on rtis from 656 women of 1545 years , residing in the field practice area . \\n this was followed by clinical examination and collection of samples for laboratory tests in urban health training centre , attached to karnataka institute of medical sciences , hubli.results:the prevalence of rtis among the reproductive age group women was 40.4% based on their symptoms , with majority having abnormal vaginal discharge . \\n the prevalence of rtis based on clinical finding was 37.4% with majority having vaginitis . \\n the laboratory test revealed a prevalence of 34.3% with majority having candidiasis . \\n the influence of socio - demographic factors like increased parity , poor socio - economic conditions , poor menstrual hygiene , illiteracy has its direct effect on occurrence of rti in the community.conclusion:this depicts that whereever possible , clinical and laboratory findings should support self - reported morbidity to know the exact prevalence of any disease in the community .'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the first article and abstract\n",
        "small_ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqQjYCT2sN-p",
        "outputId": "535417ae-0391-41a3-86fe-38d05de4e463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': Value(dtype='int64', id=None), 'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None)}\n"
          ]
        }
      ],
      "source": [
        "# Print the types of data\n",
        "print(small_ds['train'].features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vF7BJa1Myli",
        "outputId": "c2540043-ee3b-472e-8977-528e68d0ad7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': ['id', 'input', 'output'], 'test': ['id', 'input', 'output']}\n"
          ]
        }
      ],
      "source": [
        "print(small_ds.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44rwj-hGMyli"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "model_name = \"google/mt5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "afe73439740945318d0edf8ed4db7df9",
            "27c9380584d142fdb205d66452dee97c",
            "4b77dcee50e744d9a629c1aaae5608f1",
            "e728545ee68f44de94820253b879a58c",
            "1e33574b40394b14bf6501d29ec66a5a",
            "e2b7e6819fa24c09bd9b6bebb07e039d",
            "4f0e9dc431c94f0ab0158eb9e23b8ad0",
            "c13595892cb8445e965110951b0798be",
            "fd26f63b88a34728a61148415b2f8251",
            "7ad68823a25444ba971c05f3b13bfd7c",
            "ae1f978e839f4c3d9142bd5f62278ce0",
            "ad276e560fe14974aa111e8606f92463",
            "61e11e0ef5504f20a8c08385a3643387",
            "7876b227b6394cc98271b63f21eff165",
            "55bc8b89dbe4418ba2616fedebd896d3",
            "6c897fb7ee0842f19410284c6bb2455c",
            "784a160195c0414eb55585d42e918697",
            "0b752da6b1f54f958074ef3d92344b17",
            "b64cc6c1ec61438f884dd2008d8dbcc2",
            "6329610e9d8f45b8bdbe5d46500ce09a",
            "9bab1d7966034f1e93af70b36253364c",
            "3bcf34df170b4364a841985e3e7b8311"
          ]
        },
        "id": "IM_8EHU3Mylj",
        "outputId": "6e4627f5-1e7c-4515-f727-a98c58b33006"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe73439740945318d0edf8ed4db7df9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/104784 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad276e560fe14974aa111e8606f92463",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/26196 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Apply preprocessing function to dataset\n",
        "tokenized_ds = small_ds.map(preprocess, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHUzczVDMylj"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ogYvPiJdvIhc",
        "outputId": "18122da1-6ad4-47ac-ec1b-c5c4f9a9e933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_135155-eu0hca37</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eeva-wallenius-hamk/mt5-finetune/runs/eu0hca37' target=\"_blank\">MT5-Summarization</a></strong> to <a href='https://wandb.ai/eeva-wallenius-hamk/mt5-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/eeva-wallenius-hamk/mt5-finetune' target=\"_blank\">https://wandb.ai/eeva-wallenius-hamk/mt5-finetune</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/eeva-wallenius-hamk/mt5-finetune/runs/eu0hca37' target=\"_blank\">https://wandb.ai/eeva-wallenius-hamk/mt5-finetune/runs/eu0hca37</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Made encoder.block.0.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.0.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.0.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.0.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight contiguous.\n",
            "Made encoder.block.0.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.0.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.0.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.1.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.1.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.1.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.1.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.1.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.1.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.1.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.2.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.2.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.2.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.2.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.2.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.2.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.2.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.3.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.3.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.3.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.3.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.3.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.3.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.3.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.4.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.4.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.4.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.4.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.4.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.4.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.4.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.5.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.5.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.5.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.5.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.5.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.5.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.5.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.6.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.6.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.6.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.6.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.6.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.6.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.6.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made encoder.block.7.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made encoder.block.7.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made encoder.block.7.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made encoder.block.7.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made encoder.block.7.layer.1.DenseReluDense.wi_0.weight contiguous.\n",
            "Made encoder.block.7.layer.1.DenseReluDense.wi_1.weight contiguous.\n",
            "Made encoder.block.7.layer.1.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.0.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.0.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.0.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.0.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight contiguous.\n",
            "Made decoder.block.0.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.0.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.0.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.0.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.0.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.0.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.0.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.1.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.1.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.1.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.1.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.1.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.1.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.1.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.1.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.1.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.1.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.1.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.2.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.2.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.2.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.2.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.2.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.2.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.2.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.2.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.2.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.2.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.2.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.3.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.3.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.3.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.3.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.3.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.3.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.3.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.3.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.3.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.3.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.3.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.4.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.4.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.4.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.4.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.4.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.4.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.4.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.4.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.4.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.4.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.4.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.5.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.5.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.5.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.5.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.5.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.5.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.5.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.5.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.5.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.5.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.5.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.6.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.6.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.6.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.6.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.6.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.6.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.6.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.6.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.6.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.6.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.6.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made decoder.block.7.layer.0.SelfAttention.q.weight contiguous.\n",
            "Made decoder.block.7.layer.0.SelfAttention.k.weight contiguous.\n",
            "Made decoder.block.7.layer.0.SelfAttention.v.weight contiguous.\n",
            "Made decoder.block.7.layer.0.SelfAttention.o.weight contiguous.\n",
            "Made decoder.block.7.layer.1.EncDecAttention.q.weight contiguous.\n",
            "Made decoder.block.7.layer.1.EncDecAttention.k.weight contiguous.\n",
            "Made decoder.block.7.layer.1.EncDecAttention.v.weight contiguous.\n",
            "Made decoder.block.7.layer.1.EncDecAttention.o.weight contiguous.\n",
            "Made decoder.block.7.layer.2.DenseReluDense.wi_0.weight contiguous.\n",
            "Made decoder.block.7.layer.2.DenseReluDense.wi_1.weight contiguous.\n",
            "Made decoder.block.7.layer.2.DenseReluDense.wo.weight contiguous.\n",
            "Made lm_head.weight contiguous.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 00:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>26.888100</td>\n",
              "      <td>26.913452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>25.254000</td>\n",
              "      <td>21.377808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>22.858600</td>\n",
              "      <td>18.791050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>20.637000</td>\n",
              "      <td>17.441799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>20.091000</td>\n",
              "      <td>16.134851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>17.663100</td>\n",
              "      <td>14.996918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>19.151400</td>\n",
              "      <td>14.194448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>17.915700</td>\n",
              "      <td>13.482185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>15.651000</td>\n",
              "      <td>13.264349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>16.612800</td>\n",
              "      <td>13.193047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=20.901301651000978, metrics={'train_runtime': 51.1932, 'train_samples_per_second': 15.627, 'train_steps_per_second': 3.907, 'total_flos': 845999505408000.0, 'train_loss': 20.901301651000978, 'epoch': 10.0})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb\n",
        "\n",
        "# Import Weights & Biases\n",
        "import wandb\n",
        "from transformers import MT5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainerCallback\n",
        "import torch\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"mt5-finetune\", name=\"MT5-Summarization\")\n",
        "\n",
        "# Load the model\n",
        "model_name = \"google/mt5-small\"\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Ensure model parameters are contiguous\n",
        "for name, param in model.named_parameters():\n",
        "    if not param.is_contiguous():\n",
        "        param.data = param.data.contiguous()\n",
        "        print(f\"Made {name} contiguous.\")\n",
        "\n",
        "# Define training arguments with W&B logging\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_dir='./logs',\n",
        "    predict_with_generate=True,\n",
        "    report_to=\"wandb\",  # Enable W&B logging\n",
        "    logging_steps=10  # Adjust how often to log metrics\n",
        ")\n",
        "\n",
        "# Define the dataset\n",
        "train_dataset = tokenized_small_ds.shuffle().select(range(80))  # 80 examples for training\n",
        "eval_dataset = tokenized_small_ds.shuffle().select(range(20, 100))  # 20 examples for evaluation\n",
        "\n",
        "# Create the Trainer with W&B logging enabled\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuLmIy5LMylj",
        "outputId": "ccfa51ba-9af2-41be-8e68-a1b2245d044d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "import evaluate\n",
        "\n",
        "# evaluate the model and check the rouge scores\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Decode predictions and labels (remove special tokens)\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in labels (ignore index) with the padding token id\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute ROUGE scores using the `evaluate` library\n",
        "    rouge_output = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_output[\"rouge1\"],\n",
        "        \"rouge2\": rouge_output[\"rouge2\"],\n",
        "        \"rougeL\": rouge_output[\"rougeL\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "pLCJolnZMylk",
        "outputId": "18c99e9c-5f5d-41d7-b860-b9c934e5916d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 13.193046569824219, 'eval_rouge1': 0.00961851830338215, 'eval_rouge2': 0.0007523018189984281, 'eval_rougeL': 0.00916387749415247, 'eval_runtime': 7.4179, 'eval_samples_per_second': 10.785, 'eval_steps_per_second': 2.696, 'epoch': 10.0}\n"
          ]
        }
      ],
      "source": [
        "# Update trainer to include costom metrics\n",
        "trainer.compute_metrics = compute_metrics\n",
        "\n",
        "# Evaluate the model\n",
        "eval_result = trainer.evaluate()\n",
        "print(eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T3WCqpI4l4a",
        "outputId": "4c0a3432-e8d6-4da0-db30-9898e66d4b1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fine-tuned-mt5/tokenizer_config.json',\n",
              " 'fine-tuned-mt5/special_tokens_map.json',\n",
              " 'fine-tuned-mt5/spiece.model',\n",
              " 'fine-tuned-mt5/added_tokens.json')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"fine-tuned-mt5\")\n",
        "tokenizer.save_pretrained(\"fine-tuned-mt5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8s2ZV_8Mylk"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, MT5ForConditionalGeneration\n",
        "\n",
        "# Load the fine-tuned tokenizer and model\n",
        "model_name = \"fine-tuned-mt5\"\n",
        "new_tokenizer = T5Tokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
        "new_model = MT5ForConditionalGeneration.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FzPu_aVSDt",
        "outputId": "0c4eae3d-d850-4f5f-ee7f-06aff8fb1d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "of psoriasis, and its potential health risks: 1. Psoriasis is an autoimmune condition that leads to inflammation in the skin.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "\n",
        "# Restructured input\n",
        "text = (\n",
        "    \"Summarize the following information regarding psoriasis, its effects on skin health, and its potential health risks:\\n\\n\"\n",
        "    \"1. Psoriasis is an autoimmune condition that leads to inflammation in the skin.\\n\"\n",
        "    \"2. Immune system dysfunction causes inflammatory cells to accumulate in the dermis, the middle layer of the skin.\\n\"\n",
        "    \"3. The condition accelerates skin cell growth, with skin cells shedding more quickly than usual.\\n\"\n",
        "    \"4. This abnormal shedding results in uncomfortable symptoms like raised plaques, scales, and redness.\\n\"\n",
        "    \"5. Psoriasis not only affects the skin but also increases the risk of serious health issues, including heart disease, cancer, and inflammatory bowel disease.\\n\\n\"\n",
        "    \"Please provide a summary.\"\n",
        ")\n",
        "\n",
        "\n",
        "# define the device (GPU or CPU)\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Lload the summarizing pipeline\n",
        "summarizer = pipeline(\"summarization\", model=new_model, tokenizer=new_tokenizer, device=device)\n",
        "\n",
        "# summarize the text\n",
        "summary = summarizer(text,\n",
        "                     max_length=120,\n",
        "                     min_length=30,\n",
        "                     do_sample=False,\n",
        "                     num_beams=5,\n",
        "                     repetition_penalty=5.0,\n",
        "                     no_repeat_ngram_size=2,\n",
        "                     length_penalty=1.0)[0][\"summary_text\"]\n",
        "# Clean the summary by removing the <extra_id_X> token\n",
        "import re\n",
        "pattern = r\"<(extra_id_\\d+|id_\\d+)>\"\n",
        "cleaned_summary = re.sub(pattern, \" \", summary).strip()\n",
        "\n",
        "print(cleaned_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9yx5MnSMylk",
        "outputId": "86a0151e-380e-4f6b-d88e-eff5b9b99b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.12-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.3.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading PyMuPDF-1.24.12-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, PyMuPDF, orjson, markupsafe, h11, ffmpy, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed PyMuPDF-1.24.12 aiofiles-23.2.1 fastapi-0.115.3 ffmpy-0.4.0 gradio-5.3.0 gradio-client-1.4.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.1 markupsafe-2.1.5 orjson-3.10.10 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.0 semantic-version-2.10.0 starlette-0.41.0 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7ad60fc247de4d61939dd03ca60b68f5",
              "pip_warning": {
                "packages": [
                  "huggingface_hub",
                  "markupsafe"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b680b19022ea163620.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b680b19022ea163620.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "!pip install gradio PyMuPDF\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import T5Tokenizer, MT5ForConditionalGeneration\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Load the fine-tuned tokenizer and model\n",
        "model_name = \"fine-tuned-mt5\"\n",
        "new_tokenizer = T5Tokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
        "new_model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Function to extract text from PDF using PyMuPDF\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    # Open the PDF file\n",
        "    with fitz.open(pdf_file) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()  # Extract text from each page\n",
        "    return text\n",
        "\n",
        "# Summarization function\n",
        "def summarize_pdf(pdf_file, max_summary_length):\n",
        "    # Extract text from the PDF\n",
        "    input_text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    # Tokenize the input to check length\n",
        "    tokenized_input = new_tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Generate the summary\n",
        "        summary_ids = new_model.generate(\n",
        "            tokenized_input,\n",
        "            max_length=max_summary_length,\n",
        "            min_length=30,\n",
        "            num_beams=15,\n",
        "            repetition_penalty=5.0,\n",
        "            no_repeat_ngram_size=2\n",
        "        )\n",
        "\n",
        "        # Decode the generated summary\n",
        "        summary = new_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        # Clean up the summary to remove unwanted tokens\n",
        "        cleaned_summary = ' '.join([token for token in summary.split() if not token.startswith('<extra_id_')]).strip()\n",
        "\n",
        "        # Ensure the summary ends with a complete sentence\n",
        "        if cleaned_summary:\n",
        "            last_period_index = cleaned_summary.rfind('.')\n",
        "            if last_period_index != -1 and last_period_index < len(cleaned_summary) - 1:\n",
        "                cleaned_summary = cleaned_summary[:last_period_index + 1]\n",
        "            else:\n",
        "                cleaned_summary = cleaned_summary.strip()\n",
        "\n",
        "        return cleaned_summary if cleaned_summary else \"No valid summary generated.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e)  # Return the error message for debugging\n",
        "\n",
        "# Define the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=summarize_pdf,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload PDF\"),\n",
        "        gr.Slider(50, 300, step=10, label=\"Max summary length\")\n",
        "    ],\n",
        "    outputs=\"textbox\",  # A textbox for the output summary\n",
        "    title=\"PDF Text Summarizer\",\n",
        "    description=\"Upload a PDF file to summarize its content.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Launch the interface with debug mode enabled\n",
        "interface.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b752da6b1f54f958074ef3d92344b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e33574b40394b14bf6501d29ec66a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c9380584d142fdb205d66452dee97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b7e6819fa24c09bd9b6bebb07e039d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f0e9dc431c94f0ab0158eb9e23b8ad0",
            "value": "Map: 100%"
          }
        },
        "3bcf34df170b4364a841985e3e7b8311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b77dcee50e744d9a629c1aaae5608f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c13595892cb8445e965110951b0798be",
            "max": 104784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd26f63b88a34728a61148415b2f8251",
            "value": 104784
          }
        },
        "4f0e9dc431c94f0ab0158eb9e23b8ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55bc8b89dbe4418ba2616fedebd896d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bab1d7966034f1e93af70b36253364c",
            "placeholder": "​",
            "style": "IPY_MODEL_3bcf34df170b4364a841985e3e7b8311",
            "value": " 26196/26196 [01:15&lt;00:00, 348.69 examples/s]"
          }
        },
        "61e11e0ef5504f20a8c08385a3643387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784a160195c0414eb55585d42e918697",
            "placeholder": "​",
            "style": "IPY_MODEL_0b752da6b1f54f958074ef3d92344b17",
            "value": "Map: 100%"
          }
        },
        "6329610e9d8f45b8bdbe5d46500ce09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c897fb7ee0842f19410284c6bb2455c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784a160195c0414eb55585d42e918697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7876b227b6394cc98271b63f21eff165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64cc6c1ec61438f884dd2008d8dbcc2",
            "max": 26196,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6329610e9d8f45b8bdbe5d46500ce09a",
            "value": 26196
          }
        },
        "7ad68823a25444ba971c05f3b13bfd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bab1d7966034f1e93af70b36253364c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad276e560fe14974aa111e8606f92463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61e11e0ef5504f20a8c08385a3643387",
              "IPY_MODEL_7876b227b6394cc98271b63f21eff165",
              "IPY_MODEL_55bc8b89dbe4418ba2616fedebd896d3"
            ],
            "layout": "IPY_MODEL_6c897fb7ee0842f19410284c6bb2455c"
          }
        },
        "ae1f978e839f4c3d9142bd5f62278ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afe73439740945318d0edf8ed4db7df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27c9380584d142fdb205d66452dee97c",
              "IPY_MODEL_4b77dcee50e744d9a629c1aaae5608f1",
              "IPY_MODEL_e728545ee68f44de94820253b879a58c"
            ],
            "layout": "IPY_MODEL_1e33574b40394b14bf6501d29ec66a5a"
          }
        },
        "b64cc6c1ec61438f884dd2008d8dbcc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13595892cb8445e965110951b0798be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b7e6819fa24c09bd9b6bebb07e039d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e728545ee68f44de94820253b879a58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad68823a25444ba971c05f3b13bfd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_ae1f978e839f4c3d9142bd5f62278ce0",
            "value": " 104784/104784 [05:00&lt;00:00, 354.10 examples/s]"
          }
        },
        "fd26f63b88a34728a61148415b2f8251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}